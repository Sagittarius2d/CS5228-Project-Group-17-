{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "934909b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41e8b8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'data/train.csv'\n",
    "test_path = 'data/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f402cd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f45c50",
   "metadata": {},
   "source": [
    "# Drop duplicates & missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20462ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of duplicated data: (315, 17)\n"
     ]
    }
   ],
   "source": [
    "isDuplicated = train.duplicated()\n",
    "print('Shape of duplicated data:', train[isDuplicated].shape)\n",
    "train = train.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd6f01c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data of each field:\n",
      "month                  0\n",
      "town                   0\n",
      "flat_type              0\n",
      "block                  0\n",
      "street_name            0\n",
      "storey_range           0\n",
      "floor_area_sqm         0\n",
      "flat_model             0\n",
      "eco_category           0\n",
      "lease_commence_date    0\n",
      "latitude               0\n",
      "longitude              0\n",
      "elevation              0\n",
      "subzone                0\n",
      "planning_area          0\n",
      "region                 0\n",
      "resale_price           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Missing data of each field:')\n",
    "print(train.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed1c008",
   "metadata": {},
   "source": [
    "# Split X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eec91840",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.iloc[:,-1]\n",
    "X_train = train.iloc[:,:-1]\n",
    "X_test = test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7650094",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "269db817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Features: ['floor_area_sqm', 'lease_commence_date', 'latitude', 'longitude', 'elevation']\n",
      "\n",
      "Nominal Features: ['month', 'town', 'flat_type', 'block', 'street_name', 'storey_range', 'flat_model', 'eco_category', 'subzone', 'planning_area', 'region']\n"
     ]
    }
   ],
   "source": [
    "ylabel = 'resale_price'\n",
    "all_features = list(X_train.columns)\n",
    "numerical_features = list(X_train.select_dtypes(include = ['int64','float']))\n",
    "nominal_features = list(X_train.select_dtypes(include=['object']))\n",
    "print('Numerical Features: {}\\n\\nNominal Features: {}'.format(numerical_features, nominal_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3989db5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categories for nominal features:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "month             251\n",
       "town               26\n",
       "flat_type          12\n",
       "block            2472\n",
       "street_name      1103\n",
       "storey_range       25\n",
       "flat_model         20\n",
       "eco_category        1\n",
       "subzone           155\n",
       "planning_area      32\n",
       "region              5\n",
       "Name: unique, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Number of categories for nominal features:')\n",
    "X_train[nominal_features].describe().loc['unique']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0028da13",
   "metadata": {},
   "source": [
    "Drop:\n",
    "- elevation\n",
    "- eco_category\n",
    "- latitude\n",
    "- longitude\n",
    "- town\n",
    "- block\n",
    "\n",
    "Convert to number by rule:\n",
    "- month\n",
    "- flat_type\n",
    "- storey_range\n",
    "\n",
    "Target Encoding:\n",
    "- street_name\n",
    "- flat_model\n",
    "- subzone\n",
    "- planning_area\n",
    "\n",
    "One-hot encoding:\n",
    "- region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7c230a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop\n",
    "drop_features = ['elevation', 'eco_category', 'latitude', 'longitude', 'town']\n",
    "X_train.drop(drop_features, axis=1, inplace=True)\n",
    "X_test.drop(drop_features, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df687c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_to_num(blk):\n",
    "    return int(''.join(list(filter(str.isdigit, blk))))\n",
    "\n",
    "X_train['block'] = X_train['block'].apply(lambda x: block_to_num(x))\n",
    "X_test['block'] = X_test['block'].apply(lambda x: block_to_num(x))\n",
    "X_train.drop('block', axis=1, inplace=True)\n",
    "X_test.drop('block', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59929975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# month to month & year\n",
    "def month_year(data):\n",
    "    data['year'] = data['month'].apply(lambda x: x.split('-')[0]).astype('int')\n",
    "    # data['month'] = data['month'].apply(lambda x: x.split('-')[1]).astype('int')\n",
    "    data = data.drop('month', axis=1)\n",
    "    return data\n",
    "\n",
    "X_train = month_year(X_train)\n",
    "X_test = month_year(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09d5b318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.hdb.gov.sg/residential/buying-a-flat/finding-a-flat/types-of-flats\n",
    "# flat_type\n",
    "def flat_type_to_num(ft):\n",
    "    if ft=='executive':\n",
    "        return 6\n",
    "    elif ft=='multi generation':\n",
    "        return 7\n",
    "    else:\n",
    "        return int(ft.replace('-',' ').split(' ')[0])\n",
    "\n",
    "X_train['flat_type'] = X_train['flat_type'].apply(lambda x: flat_type_to_num(x))\n",
    "X_test['flat_type'] = X_test['flat_type'].apply(lambda x: flat_type_to_num(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3ce9ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storey_range\n",
    "def storey_range_to_num(sr):\n",
    "    temp = sr.split(' to ')\n",
    "    return (int(temp[0])+int(temp[1]))//2\n",
    "\n",
    "# print(X_train['storey_range'].unique())\n",
    "X_train['storey_range'] = X_train['storey_range'].apply(lambda x: storey_range_to_num(x))\n",
    "X_test['storey_range'] = X_test['storey_range'].apply(lambda x: storey_range_to_num(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d33faf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Encoding\n",
    "target_features = ['street_name', 'flat_model', 'subzone', 'planning_area']\n",
    "\n",
    "import category_encoders as ce\n",
    "target_encoder = ce.TargetEncoder(cols=target_features)\n",
    "target_encoder.fit(X_train, y_train)\n",
    "\n",
    "# transform the training and test data\n",
    "X_train = target_encoder.transform(X_train)\n",
    "X_test = target_encoder.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82c23ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding \n",
    "onehot_features = ['region']\n",
    "\n",
    "X_train = pd.get_dummies(X_train, columns=onehot_features)\n",
    "X_test = pd.get_dummies(X_test, columns=onehot_features)\n",
    "\n",
    "# keep only the common columns in the training and test data\n",
    "common_columns = X_train.columns.intersection(X_test.columns)\n",
    "X_train = X_train[common_columns]\n",
    "X_test = X_test[common_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63070660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f5aa87",
   "metadata": {},
   "source": [
    "# Predict 'resale_price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc173f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def kfold_validation(model, n_folds=5):\n",
    "    # define the k-fold cross-validation method\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    # create an empty array to store the predicted values for each fold\n",
    "    y_pred_all = np.array([])\n",
    "    # loop through each fold\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        # extract the training and test sets for this fold\n",
    "        X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        # train the model on the training set for this fold\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        # make predictions on the test set for this fold\n",
    "        y_pred_fold = model.predict(X_test_fold)\n",
    "        # append the predicted values for this fold to the array\n",
    "        y_pred_all = np.concatenate((y_pred_all, y_pred_fold))\n",
    "    # calculate the mean squared error across all folds\n",
    "    mse = ((y_pred_all - y_train) ** 2).mean()\n",
    "    # print the mean squared error\n",
    "    print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f18f750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_predict_save(model):\n",
    "    # fit the model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    # predict on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    # convert the id column of test set to a pandas dataframe\n",
    "    id_df = pd.Series([i for i in range(len(y_pred))], name='Predicted')\n",
    "    # convert y_pred to a pandas series\n",
    "    y_pred_series = pd.Series(y_pred, name='Predicted')\n",
    "    # concatenate id_df and y_pred_series horizontally\n",
    "    result_df = pd.concat([id_df, y_pred_series], axis=1)\n",
    "    # rename the columns of the concatenated dataframe\n",
    "    result_df.columns = ['Id', 'Predicted']\n",
    "    # output the result dataframe to a CSV file\n",
    "    result_df.to_csv('{}_result.csv'.format(type(model)), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216726fe",
   "metadata": {},
   "source": [
    "## 1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e9321059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 30311413042.79659\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# create a LinearRegression object\n",
    "linear_reg = LinearRegression()\n",
    "kfold_validation(linear_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b78101",
   "metadata": {},
   "source": [
    "## 2. Ridge Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f295ab1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 30316886136.897026\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# create a Ridge object with a regularization parameter of alpha=1\n",
    "ridge_reg = Ridge(alpha=1)\n",
    "kfold_validation(ridge_reg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b717a5",
   "metadata": {},
   "source": [
    "## 3. Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "51fb85f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 30316778117.19081\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# create a Lasso object with a regularization parameter of alpha=1\n",
    "lasso_reg = Lasso(alpha=1)\n",
    "kfold_validation(lasso_reg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c3ed6c",
   "metadata": {},
   "source": [
    "## 4. Elastic Net Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e833057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 17174751.59873881\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet #50189\n",
    "\n",
    "# create an ElasticNet object with a regularization parameter of alpha=1 and a mix parameter of l1_ratio=0.5\n",
    "ela_reg = ElasticNet(alpha=1, l1_ratio=0.5)\n",
    "kfold_validation(ela_reg)\n",
    "test_predict_save(ela_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b9e65a",
   "metadata": {},
   "source": [
    "## 5. Decision Tree Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9236eebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 31096689159.50097\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# create a DecisionTreeRegressor object with a maximum depth of 5\n",
    "dt_reg = DecisionTreeRegressor(max_depth=5)\n",
    "kfold_validation(dt_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2637b2c4",
   "metadata": {},
   "source": [
    "## 6. Random Forest Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "395cabe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 31000227055.841526\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# create a RandomForestRegressor object with 100 trees and a maximum depth of 5\n",
    "rf_reg = RandomForestRegressor(n_estimators=100, max_depth=5)\n",
    "kfold_validation(rf_reg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34c5f17",
   "metadata": {},
   "source": [
    "## 7. Gradient Boosting Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "985709b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 31820465549.445984\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# create a GradientBoostingRegressor object with 100 trees and a learning rate of 0.1\n",
    "gb_reg = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1)\n",
    "kfold_validation(gb_reg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67ca742",
   "metadata": {},
   "source": [
    "## 8. Support Vector Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebfbdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# create an SVR object with a radial basis function kernel and a regularization parameter of C=1\n",
    "svr_reg = SVR(kernel='rbf', C=1)\n",
    "kfold_validation(svr_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524c9e74",
   "metadata": {},
   "source": [
    "## 9. Neural Network Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab46a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# create an MLPRegressor object with 2 hidden layers of size 10 each and a learning rate of 0.1\n",
    "mlp_reg = MLPRegressor(hidden_layer_sizes=(10, 10), learning_rate_init=0.1)\n",
    "kfold_validation(mlp_reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c03140",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
